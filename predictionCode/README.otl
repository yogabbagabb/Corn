compareRPipe_python
	Actual comparison of the fits
Cross_Validation_R_Python_func_crop_model
	Code to perform the summer's week 1 objective
Note that in the following three folders, I tested the last 5 models that produced SVD errors
df_predict_dir
	See 'pipelined coding procedure' in piperesult
		The testing data sets obtained for part 1 using 
df_test_dir
	See 'pipelined coding procedure' in piperesult
		The testing data sets obtained for part 1 using 
df_train_dir
	See 'pipelined coding procedure' in piperesult
		The training data sets obtained for part 1
			Note that CV (cross validation) was done using leave one year out
lmer_data_files
	All data files obtained by predicting with lmer
piperesult
	Data files that the pipelined coding procedure creates. By pipelined coding procedure,
	I refer to the process of manipulating data in Python, predicting in R, and then
	manipulating data in R again.
result
	Data files that Yan's code saves predictions into
	Each file contains predicted data for a single specification like
		prediction_tave_spline_evi_poll_all_forward
result_in_R
	Data files that my non working R translation saves. It is not fully known
	why my R translation errs.
lmer_calculate_rmse_new_data_loo.R
	Using lmer to perform leave one year out modeling in R
		We train on 2001-2015
lmer_calculate_rmse_new_data_loo_2003_2016.R
	Using lmer to perform leave one year out modeling in R
		We train on 2003-2016
temp.R
temp2.R
	These files were used to verify information about the uniformity of evi
	data. That is, they determined whether any entries existed where eviz
	was not NA but evix was where x and z are distinct.
		I concluded that the answer is no.
	There was anothe rpurpose to these files that I forget.
lmer_calculate_rmse_new_data_loo_2003_2016_test.R
	This file is in a pristine state insofar as when Yan's models are run in this file, they perform as
	well as Yan's models in his code -- or even better
chooseKnots.R
	Allows one to select the best 2(degree) + n knots for various predictors using cpr
lmer_calculate_rmse_new_data_loo_anova.ipynb
	This was never developed. Useless.
getRange.py
	This tells us the range of values that a predictor value can take on when we practice loo over 2003 to 2016
	
	

